{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:01:25.332077Z",
     "start_time": "2021-05-05T16:59:03.222809Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Softwares\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "nlp= spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Text preprocessing, tokenizing and filtering of stopwords\n",
    "# CountVectorizer supports counts of N-grams of words or consecutive characters. Once fitted, the vectorizer has built a \n",
    "# dictionary of feature indices\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "# To transform a count matrix to a normalized tf or tf-idf representation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import gensim\n",
    "from gensim import models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model Building to Predict Aspects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T05:50:10.579171Z",
     "start_time": "2021-04-06T05:50:10.304559Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse(\"Restaurants_Train.xml\", ET.XMLParser(encoding= \"utf-8\"))\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T05:50:23.464024Z",
     "start_time": "2021-04-06T05:50:23.404185Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3044 labeled reviews.\n"
     ]
    }
   ],
   "source": [
    "labeled_reviews = []\n",
    "for sentence in root.findall(\"sentence\"):\n",
    "    entry = {}\n",
    "    aterms = []\n",
    "    aspects = []\n",
    "    sentiment = []\n",
    "    if sentence.find(\"aspectTerms\"):\n",
    "        for aterm in sentence.find(\"aspectTerms\").findall(\"aspectTerm\"):\n",
    "            aterms.append(aterm.get(\"term\"))\n",
    "    if sentence.find(\"aspectCategories\"):\n",
    "        for aspect in sentence.find(\"aspectCategories\"):\n",
    "            aspects.append(aspect.get(\"category\"))\n",
    "        for aspect in sentence.find(\"aspectCategories\"):\n",
    "            sentiment.append(aspect.get(\"polarity\"))\n",
    "            \n",
    "    entry[\"text\"], entry[\"terms\"], entry[\"aspects\"], entry[\"sentiment\"] = sentence[0].text, aterms, aspects, sentiment\n",
    "    labeled_reviews.append(entry)\n",
    "labeled_df = pd.DataFrame(labeled_reviews)\n",
    "print(\"We have\", len(labeled_reviews), \"labeled reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T05:50:43.032151Z",
     "start_time": "2021-04-06T05:50:42.956831Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "      <td>[positive, negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[service]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Not only was the food outstanding, but the lit...</td>\n",
       "      <td>[food, perks]</td>\n",
       "      <td>[food, service]</td>\n",
       "      <td>[positive, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It is very overpriced and not very tasty.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[food, price]</td>\n",
       "      <td>[negative, negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Our agreed favorite is the orrechiete with sau...</td>\n",
       "      <td>[orrechiete with sausage and chicken, waiters,...</td>\n",
       "      <td>[food, service]</td>\n",
       "      <td>[positive, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Bagels have an outstanding taste with a te...</td>\n",
       "      <td>[Bagels]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nevertheless the food itself is pretty good.</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0               But the staff was so horrible to us.   \n",
       "1  To be completely fair, the only redeeming fact...   \n",
       "2  The food is uniformly exceptional, with a very...   \n",
       "3  Where Gabriela personaly greets you and recomm...   \n",
       "4  For those that go once and don't enjoy it, all...   \n",
       "5  Not only was the food outstanding, but the lit...   \n",
       "6          It is very overpriced and not very tasty.   \n",
       "7  Our agreed favorite is the orrechiete with sau...   \n",
       "8  The Bagels have an outstanding taste with a te...   \n",
       "9       Nevertheless the food itself is pretty good.   \n",
       "\n",
       "                                               terms  \\\n",
       "0                                            [staff]   \n",
       "1                                             [food]   \n",
       "2                              [food, kitchen, menu]   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5                                      [food, perks]   \n",
       "6                                                 []   \n",
       "7  [orrechiete with sausage and chicken, waiters,...   \n",
       "8                                           [Bagels]   \n",
       "9                                             [food]   \n",
       "\n",
       "                           aspects             sentiment  \n",
       "0                        [service]            [negative]  \n",
       "1  [food, anecdotes/miscellaneous]  [positive, negative]  \n",
       "2                           [food]            [positive]  \n",
       "3                        [service]            [positive]  \n",
       "4        [anecdotes/miscellaneous]            [positive]  \n",
       "5                  [food, service]  [positive, positive]  \n",
       "6                    [food, price]  [negative, negative]  \n",
       "7                  [food, service]  [positive, positive]  \n",
       "8                           [food]            [positive]  \n",
       "9                           [food]            [positive]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save annotated reviews in a pickle file\n",
    "labeled_df.to_pickle(\"annotated_reviews_df.pkl\")\n",
    "labeled_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T05:50:47.758778Z",
     "start_time": "2021-04-06T05:50:47.718762Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>aspects</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>[staff]</td>\n",
       "      <td>[service]</td>\n",
       "      <td>[negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be completely fair, the only redeeming fact...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[food, anecdotes/miscellaneous]</td>\n",
       "      <td>[positive, negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The food is uniformly exceptional, with a very...</td>\n",
       "      <td>[food, kitchen, menu]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where Gabriela personaly greets you and recomm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[service]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For those that go once and don't enjoy it, all...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[anecdotes/miscellaneous]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  terms  \\\n",
       "0               But the staff was so horrible to us.                [staff]   \n",
       "1  To be completely fair, the only redeeming fact...                 [food]   \n",
       "2  The food is uniformly exceptional, with a very...  [food, kitchen, menu]   \n",
       "3  Where Gabriela personaly greets you and recomm...                     []   \n",
       "4  For those that go once and don't enjoy it, all...                     []   \n",
       "\n",
       "                           aspects             sentiment  \n",
       "0                        [service]            [negative]  \n",
       "1  [food, anecdotes/miscellaneous]  [positive, negative]  \n",
       "2                           [food]            [positive]  \n",
       "3                        [service]            [positive]  \n",
       "4        [anecdotes/miscellaneous]            [positive]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read annotated reviews df -> labeled dataset for training\n",
    "annotated_reviews_df = pd.read_pickle(\"annotated_reviews_df.pkl\")\n",
    "annotated_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T05:52:50.620302Z",
     "start_time": "2021-04-06T05:52:50.330312Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Convert the multi-labels into arrays\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(annotated_reviews_df.aspects) # aspects\n",
    "X = annotated_reviews_df[\"text\"] # reviews\n",
    "\n",
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size= 0.25, random_state= 0)\n",
    "\n",
    "# save the the fitted binarizer labels\n",
    "filename = 'mlb.pkl'\n",
    "pickle.dump(mlb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T05:52:53.071782Z",
     "start_time": "2021-04-06T05:52:53.063805Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,)\n",
      "(761,)\n",
      "(2283, 5)\n",
      "(761, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T05:57:58.225052Z",
     "start_time": "2021-04-06T05:57:57.506705Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8662286465177398"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelPowerset allows for multi-label classification\n",
    "# Build a pipeline for multinomial naive bayes classification\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T06:00:00.008135Z",
     "start_time": "2021-04-06T05:59:56.136559Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8633377135348226"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if SVM performs better\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', LabelPowerset(\n",
    "                             SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, max_iter=6, random_state=42)))])\n",
    "_ = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "\n",
    "#Calculate accuracy\n",
    "np.mean(predicted_svm == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T06:00:07.390610Z",
     "start_time": "2021-04-06T06:00:07.095838Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train naive bayes on full dataset and save model\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = \"english\",ngram_range=(1, 1))),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', LabelPowerset(MultinomialNB(alpha=1e-1))),])\n",
    "text_clf = text_clf.fit(X, y)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'naive_model1.pkl'\n",
    "pickle.dump(text_clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T06:00:26.802889Z",
     "start_time": "2021-04-06T06:00:26.764993Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#mlb.inverse_transform(predicted)\n",
    "pred_df = pd.DataFrame(\n",
    "    {'reviews': X_test,\n",
    "     'pred_category': mlb.inverse_transform(predicted)\n",
    "    })\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Using Glove Embeddings and SpaCY to Find Sentiment Scores across Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T17:52:18.147569Z",
     "start_time": "2021-04-30T17:44:44.449479Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading positive and negative words\n",
    "\n",
    "neg_file = open(\"neg_words.txt\", encoding = \"ISO-8859-1\")\n",
    "pos_file = open(\"pos_words.txt\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "neg = [line.strip() for line in neg_file.readlines()] # Readlines returns a list of the lines in the file\n",
    "pos = [line.strip() for line in pos_file.readlines()]\n",
    "\n",
    "opinion_words = neg + pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run below code only if running for the first time\n",
    "\n",
    "# Word2Vec consists of models for generating word embedding. \n",
    "# Words that occur in similar context tend to be closer to each other in vector space\n",
    " \n",
    "# glove_input_file = 'glove.6B.100d.txt' # A pre-trained model for sentiment analysis\n",
    "# glove_vec_file = 'glove.6B.100d.txt.word2vec'\n",
    "\n",
    "# word2vec = gensim.models.KeyedVectors.load_word2vec_format(glove_vec_file, binary= False)\n",
    "# KeyedVectors:  a mapping between keys and vectors.\n",
    "\n",
    "#pickle.dump(word2vec, open(\"word2vec_glove.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load above saved word embedding\n",
    "word2vec = pickle.load(open(\"./word2vec_google.pkl\", \"rb\"))\n",
    "\n",
    "# load the multi label binarizer from the aspect model that we've build above\n",
    "mlb = pickle.load(open(\"mlb.pkl\", \"rb\"))\n",
    "\n",
    "# load the fitted Naive Bayes Model\n",
    "naive_model1 = pickle.load(open(\"naive_model1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T17:52:20.090525Z",
     "start_time": "2021-04-30T17:52:19.638621Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ambience', 'anecdotes/miscellaneous', 'food', 'price', 'service'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes in Multi Label Binarizer\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T17:52:21.424393Z",
     "start_time": "2021-04-30T17:52:20.126604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def check_similarity(aspects, word):\n",
    "    # checks for similarity between the aspect and given word and returns the most similar aspect for the given word\n",
    "    similarity = []\n",
    "    for aspect in aspects:\n",
    "        similarity.append(word2vec.n_similarity([aspect], [word]))\n",
    "        # setting throeshold for maximum similarity\n",
    "    if max(similarity) > .20:\n",
    "        return aspects[np.argmax(similarity)] # Returns the indices of the maximum value\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def assign_term_to_aspect(aspect_sent, terms_dict, sent_dict, pred):\n",
    "    \n",
    "    # This function takes in a Sentiment dictionary and appends the aspect dictionary \n",
    "    # aspect_sent: Total sentiment tally\n",
    "    # terms_dict: Dictionary with individual aspects and their associated sentiments\n",
    "    # sent_dict: Counter of the form : Counter(term: sentiment score)\n",
    "    # returns two types of aspect dictionaries: updated terms_dict and aspect_sent\n",
    "    \n",
    "    aspects = [\"ambience\", \"food\", \"price\", \"service\"]\n",
    "    \n",
    "    # checking word2vec\n",
    "    \n",
    "    for term in sent_dict:\n",
    "        try:\n",
    "            # Conditions for when to use the NB Classifier by default vs word2vec\n",
    "            if check_similarity(aspects, term.split()[-1]): # use .split() because word2vec can't process Compund Nouns\n",
    "                terms_dict[check_similarity(aspects, term.split()[-1])][term] += 1\n",
    "                if sent_dict[term] > 0:\n",
    "                    aspect_sent[check_similarity(aspects, term.split)][\"pos\"] += sent_dict[term]\n",
    "                else:\n",
    "                    aspect_sent[check_similarity(aspects, term.split)][\"neg\"] += abs(sent_dict[term])\n",
    "            elif(pred[0] ==  \"anecdotes/miscellaneous\"):\n",
    "                continue\n",
    "            elif(len(pred) == 1):\n",
    "                terms_dict[pred[0]][term] += 1\n",
    "                if sent_dict[term] > 0:\n",
    "                    aspect_sent[pred[0]][\"pos\"] += sent_dict[term]\n",
    "                else:\n",
    "                    aspect_sent[pred[0]][\"neg\"] += abs(sent_dict[term])\n",
    "                    \n",
    "            # if unable to classify via NB Classifier or word2vec and then put it in miscellaneous bucket\n",
    "            else:\n",
    "                terms_dict[\"misc\"][term] += 1\n",
    "                if sent_dict[term] > 0:\n",
    "                    aspect_sent[\"misc\"][\"pos\"] += sent_dict[term]\n",
    "                else:\n",
    "                    aspect_sent[\"misc\"][\"neg\"] += abs(sent_dict[term])\n",
    "                    \n",
    "        except:\n",
    "            continue\n",
    "    return aspect_sent, terms_dict\n",
    "\n",
    "\n",
    "def feature_sentiment(sentence):\n",
    "    # input: dictionary and sentence\n",
    "    # this function appends dictionary with new features if features didn't exist previously then updates sentiments\n",
    "    # to each of the new and oexistingld features\n",
    "    # returns updated dictionary\n",
    "    \n",
    "    sent_dict = Counter()\n",
    "    sentence = nlp(sentence)\n",
    "    debug = 0\n",
    "    for token in sentence:\n",
    "        # check if word is an opinion word then assign a sentiment\n",
    "        if token.text in opinion_words:\n",
    "            sentiment = 1 if token.text in pos else -1\n",
    "            # if target is an adverb modifier (eg: pretty, highly, etc.) but also an opinion word, ignore and pass\n",
    "            if token.dep_ == \"advmod\":\n",
    "                continue\n",
    "            elif token.dep_ == \"amod\": # opinion words that are adjectives, verbs, adverbs, etc.\n",
    "                sent_dict[token.head.text] += sentiment\n",
    "                \n",
    "            else:\n",
    "                for child in token.children:\n",
    "                    #  It checks for child tokens for each adjective and picks up the adverbs\n",
    "                    # if there is an adjective modifier (eg: pretty, very, etc.), then add more weight to sentiment\n",
    "                    if((child.dep_ == \"amod\") or (child.dep_ == \"advmod\")) and (child.text in opinion_words):\n",
    "                        sentiment *= 1.5\n",
    "                    # add negative sentiment for negative words\n",
    "                    if child.dep_ == \"neg\":\n",
    "                        sentiment *= -1\n",
    "                    \n",
    "                for child in token.children:\n",
    "                    # if it's a verb then check if it's a direct object\n",
    "                    # direct object is the noun or noun phrase that's receiving the action of the verb\n",
    "                    if (token.pos_ == \"VERB\") & (child.dep_ == \"dobj\"):\n",
    "                        sent_dict[child.text] += sentiment\n",
    "                    \n",
    "                        # check for conjugates (both a and b) and add them to dictionary\n",
    "                        subchildren = []\n",
    "                        conj = 0\n",
    "                        for subchild in child.children:\n",
    "                            if subchild.text == \"and\":\n",
    "                                conj = 1\n",
    "                            if (conj == 1) and (subchild.text != \"and\"):\n",
    "                                subchildren.append(subchild.text)\n",
    "                                conj = 0\n",
    "                        for subchild in subchildren:\n",
    "                            sent_dict[subchild] += sentiment\n",
    "                            \n",
    "                # check for negation\n",
    "                for child in token.head.children:\n",
    "                    noun = \"\"\n",
    "                    if ((child.dep_ == \"amod\") or (child.dep_ == \"advmod\")) and (child.text in opinion_words):\n",
    "                        sentiment *= 1.5\n",
    "                    # check for negation words and flip the sign of sentiment\n",
    "                    if (child.dep_ == \"neg\"): \n",
    "                        sentiment *= -1\n",
    "                        \n",
    "                # check for nouns\n",
    "                for child in token.head.children:\n",
    "                    noun = \"\"\n",
    "                    if (child.pos_ == \"NOUN\") and (child.text not in sent_dict):\n",
    "                        noun = child.text\n",
    "                        # Also, check for compound nouns\n",
    "                        for subchild in child.children:\n",
    "                            if subchild.dep_ == \"compound\":\n",
    "                                noun = subchild.text + \" \" + noun\n",
    "                        sent_dict[noun] += sentiment\n",
    "                    debug += 1\n",
    "                \n",
    "    return sent_dict\n",
    "\n",
    "def classify_and_sent(sentence, aspect_sent, terms_dict):\n",
    "    # classifies the sentence into a category and assign a sentiment\n",
    "    # aspect_dict: parent dictionary with all aspects\n",
    "    # input the sentence and aspect dictionary which is going to be updated\n",
    "    # output will be the updated aspect dictionary\n",
    "    \n",
    "    # classify the sentence using NB Classifier\n",
    "    predicted = naive_model1.predict([sentence])\n",
    "    pred = mlb.inverse_transform(predicted)\n",
    "\n",
    "    # this will take your labels and transform them back to the classes with the encoding.     \n",
    "    # get aspect names and repective sentiments in dictionary form\n",
    "    sent_dict = feature_sentiment(sentence)\n",
    "    \n",
    "    # categorize the aspect names into given 4 aspects in aspect_dict\n",
    "    aspect_sent, terms_dict = assign_term_to_aspect(aspect_sent, terms_dict, sent_dict, pred[0])\n",
    "    return aspect_sent, terms_dict\n",
    "\n",
    "def split_sentence(text):\n",
    "    # splits review into list of sentences using spacy's sentence parser\n",
    "    \n",
    "    review = nlp(text)\n",
    "    bag_sentence = []\n",
    "    start = 0\n",
    "    for token in review:\n",
    "        if token.sent_start == 1:\n",
    "            bag_sentence.append(review[start: (token.i-1)])\n",
    "            start = token.i # index\n",
    "            \n",
    "        if token.i == len(review)-1:\n",
    "            bag_sentence.append(review[start: (token.i+1)])\n",
    "    return bag_sentence\n",
    "\n",
    "# remove special characters using regex\n",
    "def remove_special_char(sentence):\n",
    "    return re.sub(r\"[^a-zA-Z0-9.',:;?]+\", \" \", sentence)\n",
    "\n",
    "def review_pipe(review, aspect_sent, terms_dict= {\"ambience\": Counter(), \"food\": Counter(), \"price\": Counter(), \n",
    "                                                  \"service\": Counter(), \"misc\": Counter()}):\n",
    "    sentences = split_sentence(review)\n",
    "    for sentence in sentences:\n",
    "        sentence = remove_special_char(str(sentence))\n",
    "        aspect_sent, terms_dict = classify_and_sent(sentence.lower(), aspect_sent, terms_dict)\n",
    "    return aspect_sent, terms_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Test Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T17:52:32.694424Z",
     "start_time": "2021-04-30T17:52:32.557429Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sushi': 1, 'waiter': 1, 'music': -1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test code for feature_sentiment\n",
    "\n",
    "sentence= \"I came here with my friends on a Tuesday night. The sushi here is amazing. Our waiter was very helpful, but the music was terrible.\"\n",
    "feature_sentiment(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T17:52:35.072120Z",
     "start_time": "2021-04-30T17:52:32.728423Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ambience': Counter(),\n",
       "  'food': Counter(),\n",
       "  'price': Counter(),\n",
       "  'service': Counter(),\n",
       "  'misc': Counter()},\n",
       " {'ambience': Counter({'music': 1}),\n",
       "  'food': Counter({'waiter': 1}),\n",
       "  'price': Counter(),\n",
       "  'service': Counter(),\n",
       "  'misc': Counter()})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test code for review_pipe\n",
    "\n",
    "terms_dict = {\"ambience\": Counter(), \"food\": Counter(), \"price\": Counter(), \"service\": Counter(), \"misc\": Counter()}\n",
    "aspect_sent = {\"ambience\": Counter(), \"food\": Counter(), \"price\": Counter(), \"service\": Counter(), \"misc\": Counter()}\n",
    "review = \"Our waiter was not very helpful, and the music was terrible.\"\n",
    "review_pipe(review, aspect_sent, terms_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-30T17:52:35.436691Z",
     "start_time": "2021-04-30T17:52:35.170950Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I came here with my friends on a Tuesday night,\n",
       " The sushi here is amazing,\n",
       " Our waiter was very helpful, but the music was terrible.]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test code for split_sentence\n",
    "\n",
    "split_sentence(\"I came here with my friends on a Tuesday night. The sushi here is amazing. Our waiter was very helpful, but the music was terrible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Dataset"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.22200000000001,
   "position": {
    "height": "40px",
    "left": "1436.67px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
